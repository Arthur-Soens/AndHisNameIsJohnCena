#!/usr/bin/env python
# coding: utf-8

# # Машинное обучение, ФКН ВШЭ
# 
# ## Практическое задание 8
# 
# ### Общая информация
# 
# Дата выдачи: 30.05.2017
# 
# Срок сдачи: 23:59MSK 07.06.2017
# 
# ### О задании
# 
# Практическое задание 8 посвящено применению различных подходов к решению задачи ранжирования. В рамках данного задания вы:
#  * рассмотрите задачу ранжирования в контексте поискового ранжирования документов по запросу;
#  * реализуете pointwise и pairwise подходы с использованием линейных моделей и градиентного бустинга к решению задачи ранжирования.
# 
# ### Оценивание и штрафы
# 
# Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.
# 
# Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.
# 
# Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник). 
# 
# Неэффективная реализация кода может негативно отразиться на оценке.
# 
# 
# ### Формат сдачи
# Для сдачи задания переименуйте получившийся файл \*.ipynb в соответствии со следующим форматом: *HW8_Username.ipynb*, где *Username* — Ваша фамилия и инициалы на латинице (например, *HW8_IvanovII.ipynb*). Далее отправьте этот файл на hse.cs.ml+<номер группы>@gmail.com (например, hse.cs.ml+141@gmail.com для студентов группы БПМИ-141).

# ## Ранжирование
# 
# ### Данные
# 
# В рамках данного задания в качестве исследуемого набора данных будем рассматривать данные конкурса [Интернет-математика 2009](https://academy.yandex.ru/events/data_analysis/grant2009/).
# 
# ### Проверим интуицию
# 
# Для начала вопрос, который не будет оцениваться, но нужен для проверки вашей интуиции на выбор наилучшей модели. Какой из следующих подходов позволит достичь наилучшего качества ранжирования:
#  * pointwise подход с использованием линейных моделей;
#  * pointwise подход с использованием градиентного бустинга;
#  * pairwise подход с использованием линейных моделей;
#  * pairwise подход с использованием градиентного бустинга?

# ### Загружаем данные
# 
# Загрузите обучающую выборку конкурса [Интернет-математика 2009](https://academy.yandex.ru/events/data_analysis/grant2009/). Данные предоставлены в формате [SVM light](http://svmlight.joachims.org). Обратите внимание, что одной строчкой в файле является **пара** запрос-документ.

# **1. (1 балл)** Загрузите данные из файла imat2009_learning.txt и разбейте их в соотношении 70/20/10 на обучающую, валидационную и тестовую выборки (необходимо разбивать по запросам, а не по строкам).

# In[ ]:


# Your code here

# ### Метрика
# 
# В качестве метрики в рамках данного задания будем использовать среднее значение nDCG@10 по запросам. Напомним, что nDCG@10 является нормированным аналогом метрики DCG@10, которая вычисляется по формуле:
# $$\text{DCG@10}(q) = \sum_{i=1}^{10} \frac{2^{\mathrm{rel}_i} - 1}{\log_2(i+1)},$$
# где $q$ — запрос, а $\mathrm{rel}_i$ – релевантность $i$-го документа (в отсортированном по убыванию релевантности запросу $q$ списке).

# **2. (1 балл)** Оцените матожидание nDCG@10 для случайного ранжирования документов на тестовой выборке. Для этого несколько раз рассмотрите случайную перестановку документов для каждого из запросов, вычислив значение метрики для полученного ранжирования, и усредните полученные значения.

# In[ ]:


# Your code here

# ### Pointwise подход с использованием линейных моделей
# 
# В этом подходе предлагается использовать в качестве целевой переменной оценку ассесора из выборки и таким образом решать задачу регрессии, а не ранжирования. Тем не менее, качество алгоритма мы будем оценивать по nDCG@10.

# **3. (1 балл)** Обучите свою любимую имплементацию линейной регрессии и выведите значение nDCG@10 на тестовой выборке.

# In[ ]:


# Your code here

# **4. (1 балл)** Выведите значение метрики на кросс-валидации с 5 фолдами на полной выборке из п. 1 для более точной оценки nDCG@10 (все объекты для одного запроса должны попадать в один фолд при разбиении).

# In[ ]:


# Your code here

# ### Pairwise подход с использованием линейных моделей
# 
# В рамках pairwise подхода предлагается решать задачу классификации на парах объектов (в нашем случае объект=запрос-документ). А именно, для каждой пары объектов мы обучаем алгоритм предсказывать вероятность того, что первый объект должен находится выше в ранжированном списке.

# **5. (2 балла)** Используйте имплементацию [SVM light](http://svmlight.joachims.org) для обучения линейной pairwise модели и выведите значение nDCG@10 на тестовой выборке, подобрав оптимальное значение $C$ на валидационной выборке  (рассмотрите хотя бы 3 различных значения).

# In[ ]:


# Your code here

# ### Pointwise подход с использованием градиентного бустинга

# **6. (1 балл)** Используйте XGBoost в режиме регрессии для предсказания оценок ассесоров и выведите значение nDCG@10 на тестовой выборке.

# In[ ]:


# Your code here

# ### Pairwise подход с использованием градиентного бустинга

# **7. (1 балл)** Обучите XGBoost в режиме ранжирования (objective="rank:pairwise"), выбрав nDCG в качестве метрики eval_metric, и выведите значение nDCG@10 на тестовой выборке.

# In[ ]:


# Your code here

# **8. (1 балл)** Попробуйте настраивать разные гиперпараметры XGBoost'а. Приведите исследуемые множества гиперпараметров и полученные на них результаты. Удалось ли вам добиться прироста в качестве? Убедитесь, что вы использовали оптимальное количество базовых алгоритмов в построенных композициях.

# In[ ]:


# Your code here

# ### Выводы

# **9. (1 балл)** Сравните все рассмотренные методы. Какой метод даёт наилучшее качество? Совпало ли это с вашей первоначальной интуицией?

# In[ ]:


# Your code here
