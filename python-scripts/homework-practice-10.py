#!/usr/bin/env python
# coding: utf-8

# # Машинное обучение, ФКН ВШЭ
# ## Практическое задание 10
# 
# ### Общая информация
# 
# Дата выдачи: 22.04.2019
# 
# Мягкий дедлайн: 12.05.2019 08:00 MSK
# 
# Жёсткий дедлайн: 14.05.2019 23:59 MSK
# 
# ### Оценивание и штрафы
# 
# Каждая из задач имеет определенную «стоимость», которая будет объявлена после жёсткого дедлайна. Максимально допустимая оценка за работу — 10 баллов.
# 
# Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.
# 
# Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).
# 
# Неэффективная реализация кода может негативно отразиться на оценке.
# 
# В финальной версии ноутбука, которая отправляется для сдачи задания, должны быть быть выполнены следующие условия:
# * все ячейки выполнены для представленной в ноутбуке версии кода;
# * результаты выполнения ячеек отображены и согласованы с кодом;
# * при повторном запуске ячеек результаты должны воспроизводиться с точностью до случайности.
# 
# 
# ### Формат сдачи
# 
# Задания сдаются через систему anytask. Посылка должна содержать:
# 
# * Ноутбук homework-practice-10-Username.ipynb
# 
# Username — ваша фамилия и имя на латинице именно в таком порядке

# # Часть 1. Работа с данными
# 

# Мы будем работать с датасетом `20newsgroups`. В датасете содержится около 20 000 статей, разбитых на 20 классов. В ячейке ниже происходит загрузка датасета:

# In[ ]:


import numpy as np
from sklearn.model_selection import train_test_split

# In[ ]:


from sklearn.datasets import fetch_20newsgroups
dataset = fetch_20newsgroups(subset='all')
data = dataset["data"]
y = np.array(dataset["target"])
labels_names = {i: name for i, name in enumerate(dataset["target_names"])}

# In[ ]:


print("Target names: " + ", ".join(dataset["target_names"]))

# Эти маски нам понадобятся позднее

# In[ ]:


train_mask = (np.random.uniform(size=len(data)) < 0.2)
test_mask = ~train_mask

# **Задание 1 (1 балл)**. Для работы с текстами нам нужно как-то построить их признаковое описание. По-простому это можно сделать как минимум тремя способами:
# * посчитать tf-idf векторы;
# * усреднить предобученные эмбеддинги (например, Word2Vec);
# * обучить эмбеддинги самому (тот же Word2Vec) и усреднить их.
# 
# Кроме того, в каждом из этих случаев можно провести [стемминг](https://en.wikipedia.org/wiki/Stemming) токенов, а можно обойтись без него. Какие плюсы и минусы есть у стемминга?
# 
# В дальнейшем мы захотим обучить для этого датасета KMeans (мы надеемся, что в один кластер попадут документы с одной тематикой). Изучите датасет (его размер, размер текстов, тематики, пр.) и скажите, какие есть плюсы и минусы у каждого из трех описанных выше подходов.

# In[ ]:


# Your code here

# __*Ответ:*__

# **Задание 2 (1 балл)**. Удалите из текстов email-адреса, приведите все к нижнему регистру, токенизируйте тексты с помощью `gensim.parsing.preprocessing.preprocess_string` (необходимые фильтры уже были импортированы) и обучите на полученных данных `gensim.models.word2vec.Word2Vec` с параметрами по умолчанию и 30 итерациями в обучении. Дополнительно обучите еще один Word2Vec на текстах с произведенным стеммингом, используйте `nltk.stem.porter.PorterStemmer`.

# In[ ]:


from gensim.parsing.preprocessing import (
    preprocess_string,
    strip_tags,
    strip_punctuation,
    strip_multiple_whitespaces,
    strip_numeric,
    remove_stopwords,
)
from gensim.models.word2vec import Word2Vec
from nltk.stem.porter import PorterStemmer
import re

EMAIL_REGEXP = r"([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+)"

w2v = # Your code here
stemmed_w2v = # Your code here

# Напишите функцию, которая принимала бы на вход токенизированные тексты и для каждого текста возвращала бы усредненный эмбеддинг токенов. Если для какого-то токена в модели нет эмбеддинга, считайте его равным нулевому вектору.

# In[ ]:


def average_embedding(texts, embedder):
    '''
    texts -- список из списков токенов (каждый вложенный список соответствует тексту)
    embedder -- объект с полем wv, у которого определен оператор [], и с полем vector_size
    return: матрица усредненных эмбеддингов
    '''
    
    # Your code here

# Воспользуйтесь этой функцией, чтобы составить матрицу средних word2vec-эмбеддингов для наших текстов.

# In[ ]:


# Your code here

# **Задание 3 (бонус, 0.5 баллов)**. Классической рекламой Word2Vec является "осмысленность арифметических действий" над эмбеддингами: утверждается, например, что $\text{embedding(king)} - \text{embedding(man)} + \text{embedding(woman)} \approx \text{embedding(queen)}$. Можете попробовать поискать такие отношения в вашей обученной модели. Получилось ли у вас что-нибудь найти? Подсказка: воспользуйтесь `w2v.wv.similar_by_vector`

# In[ ]:


# Your code here

# **Задание 4 (1 балл)**. В дальнейшем нам понадобится уметь считать качество кластеризации, будем использовать supervised-метрики. Напишите функцию, вычисляющую BCubed-precision, BCubed-recall и BCubed-F1

# In[ ]:


def bcubed_metrics(labels, clusters):
    '''
    labels -- настоящие метки документов
    clusters -- соответственно, кластеры для документов
    return: precision, recall, f1
    '''
    
    # Your code here

# Чтобы понимать, насколько плохой/хорошей получилась кластеризация, нужно как минимум понимать, насколько она лучше случайной кластеризации. Случайно кластеризуйте объекты и посчитайте метрики.

# In[ ]:


# Your code here

# Напишите функцию, которая рисовала бы график распределения меток в каждом из кластеров, например, как на картинке.
# <img src="example.png" align="center">

# In[ ]:


def plot_labels_distribution(labels, clusters, labels_names):
    '''
    labels -- настоящие классы документов
    clusters -- соответственно, кластеры для документов
    labels_names -- словарь, сопоставляющий индексу класса его название
    '''
    
    # Your code here

# # Часть 2. Кластеризация

# **Задание 5 (1 балл, без ответа на вопросы максимум 0.5 баллов)**. Обучите на усредненных word2vec-векторах (и для текстов со стеммингом, и без него) KMeans на 20 кластеров (с параметрами по умолчанию), измерьте качество кластеризации (BCubed-метрики) и постройте график распределения меток по кластерам. Попробуйте поперебирать параметры KMeans, не меняя число кластеров. Получилось ли у вас добиться сильного выигрыша?

# In[ ]:


# Your code here

# Помог ли стемминг улучшить качество кластеризации? Насколько сильно?
# 
# **_Ответ_**:
# 
# Все следующие эксперименты проводите на текстах без стемминга. 

# **Задание 6 (1.5 балла, без ответа на вопросы максимум 1 балл)**. Скорее всего, выигрыш оказался очень маленьким. Возможно, в усредненных word2vec-векторах содержится слишком мало информации, и этим объясняется низкое качество модели? Чтобы проверить это, обучите логистическую регрессию на предсказание настоящих меток документов. Для разбиения на обучающую и тестовую выборки воспользуйтесь масками `train_mask`, `test_mask`. Измерьте BCubed-метрики на тестовой части для кластеризации и логистической регрессии. Для кластеризации также постройте график распределения меток по кластерам.

# In[ ]:


# Your code here

# Посмотрите на размер кластеров. Сильно ли они отличаются друг от друга? Есть ли очень большие или очень маленькие кластеры?

# In[ ]:


# Your code here

# Можно ли объяснить плохую кластеризацию тем, что усредненный Word2Vec - слишком плохое признаковое пространство? Если такого утверждения сделать нельзя, дело может быть в слишком похожих метках документов. Попробуйте оставить в выборках только документы с 7 сильно отличающимися классами. Обучите KMeans и логистическую регрессию на этих данных; изменился ли зазор между кластеризацией и классификацией?

# In[ ]:


distinct_labels = {
    "comp.graphics", "rec.autos", "rec.sport.baseball",
    "sci.space", "sci.med", "soc.religion.christian", "talk.politics.guns"
}

# Your code here

# Ответьте на вопросы:
# 1. Судя по графикам, какие классы сложно отделяются от других? Какие классы похожи друг на друга? Какие классы легко отделяются от других?
# 2. Возросли ли метрики у кластеризации при отборе 7 отличных друг от друга меток?
# 3. Возросли ли метрики у классификации при отборе 7 отличных друг от друга меток? Почему?
# 4. Можно ли объяснить плохую кластеризацию неудачным признаковым пространством? Схожестью меток?

# **_Ответ:_**

# # Часть 3. Latent Dirichlet Allocation

# **Задание 7 (1.5 балла)**. Обучать LDA на тех текстах, которые мы сейчас имеем, - очень медленно, поскольку в них очень много уникальных слов. Чтобы это исправить, мы оставим в текстах только те слова, которые чаще всего встречаются в нашем корпусе. Напишите функцию, которая принимает на вход тексты и количество слов, которые нужно оставить, и выкидывает слова, которые не попали в _глобальный_ топ по всему корпусу:

# In[ ]:


from collections import Counter

def leave_top_words(texts, n_words):
    '''
    texts -- набор текстов (список списков токенов)
    n_words -- сколько слов из топа нужно оставить
    return: набор текстов с удаленными словами, которые не вошли в топ
    '''
    
    # Your code here

# Сделайте два набора текстов: в одном оставьте 3000 слов, а в другом 6000 слов.

# In[ ]:


# Your code here

# Обучите `gensim.models.ldamodel.LdaModel` (для этого вам также понадобится `gensim.corpora.Dictionary`) с 20 темами на обоих наборах текстов.

# In[ ]:


from gensim.corpora import Dictionary
from gensim.models.ldamodel import LdaModel

# Your code here

# Метод `inference` в LDA возвращает для каждого текста вероятности тем. Напишите функцию, которая принимала бы обученную LDA-модель и корпус, возвращая самый вероятный топик для каждого текста. Убедитесь, что разница в качестве (по BCubed) между наборами на 3000 и 6000 слов незначительна. Это будет означать, что можно работать с набором на 3000 слов.

# In[ ]:


def get_topics(lda_model, corpus):
    '''
    lda_model -- обученный инстанс LdaModel
    corpus -- корпус
    return: наиболее вероятный топик для каждого текста из корпуса
    '''
    
    # Your code here

# **Задание 8 (1 балл, без ответа на вопросы максимум 0.5 балла)**. Попытайтесь выбить из LDA больше качества. Для этого переберите по полной квадратной сетке параметры `iterations` и `num_passes` (скажем, по сетке 3х3, не стоит ставить слишком большие значения). Для каждой модели посчитайте ELBO и bcubed-метрики и сохраните их: они нам понадобятся в дальнейшем. Постройте графики зависимости ELBO от `iterations` при разных `num_passes` (3 кривые на одном графике) и наоборот.

# In[ ]:


# Your code here

# Постройте график зависимости BCubed-F1 от ELBO. Для лучшей (по BCubed-F1) LDA-модели постройте график распределения меток в кластерах.

# In[ ]:


# Your code here

# Ответьте на вопросы:
# 1. Посмотрите на размер кластеров в LDA. Сильно ли они отличаются друг от друга? Есть ли очень большие или очень маленькие кластеры?
# 2. Как влияют на ELBO `iterations` и `passes`? 
# 3. Есть ли какая-нибудь зависимость между ELBO и BCubed-F1? Можем ли мы обучать LDA, смотря только на ELBO?
# 4. Сравните тематическое моделирование при помощи LDA и кластеризацию при помощи KMeans.

# **Задание 9 (0.5 балла)**. С помощью `pyLDAvis.gensim` визуализируйте найденные моделью темы и попытайтесь описать некоторые из них.

# In[ ]:


# Your code here

# # Часть 4. Три подхода к обучению

# **Задание 10 (1.5 балла, без ответа на вопросы максимум 1)**. Вы обучили две unsupervised-модели и, скорее всего, не получили очень хорошего качества. Более того, вы попытались обучить логистическую регрессию на небольшом количестве размеченных данных и, скорее всего, получили качество заметно лучше. Попробуйте теперь обучить логистическую регрессию на tf-idf векторах. Сравните качество с логистической регрессией на усредненных word2vec-векторах. Для разбиения на обучающую и тестовую выборки пользуйтесь масками `train_mask` и `test_mask`.

# In[ ]:


# Your code here

# Попробуем применить semi-supervised подход. На тех же данных примените self-training метод, в основе которого лежит логистическая регресиия. Напомним, что это означает:
# 
# 1. Обучаем модель на размеченной выборке;
# 2. Применяем модель к неразмеченной выборке, выбираем некоторое количество объектов, в которых модель уверена больше всего. Добавляем к размеченной выборке эти объекты, присваивая им метки, которые предсказала модель;
# 3. Повторяем несколько раз.
# 
# В качестве неразмеченной части возьмите тестовую выборку. Посчитайте метрики

# In[ ]:


# Your code here

# Ответьте на вопросы:
# 1. Как методы ранжируются по итоговому качеству? Почему именно так?
# 2. На каком признаковом пространстве логистическая регрессия дает лучшее качество? Почему?
# 
# **_Ответ_**:
